{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e92976-2559-4e72-8d14-1c2dd4477ef1",
   "metadata": {},
   "source": [
    "## PIPELINE QUI recupere les tweets recents sur chaque equipe \n",
    "### ==>fait un calcul NLP pour avoir une valeur de polarité\n",
    "### ==>La sortie un BDD envoyé dans BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a49c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.9.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.0/757.0 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.3.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.9.13\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-4.10.1-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.27.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2022.6.15.2)\n",
      "Installing collected packages: tweepy\n",
      "Successfully installed tweepy-4.10.1\n",
      "Collecting textBlob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from textBlob) (3.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textBlob) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textBlob) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textBlob) (4.64.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textBlob) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.1->textBlob) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.1->textBlob) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.1->textBlob) (4.3.0)\n",
      "Installing collected packages: textBlob\n",
      "Successfully installed textBlob-0.17.1\n",
      "Collecting textblob_fr\n",
      "  Downloading textblob_fr-0.2.0-py2.py3-none-any.whl (561 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.2/561.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: textblob>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from textblob_fr) (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from textblob>=0.8.0->textblob_fr) (3.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob>=0.8.0->textblob_fr) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob>=0.8.0->textblob_fr) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob>=0.8.0->textblob_fr) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob>=0.8.0->textblob_fr) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.1->textblob>=0.8.0->textblob_fr) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.1->textblob>=0.8.0->textblob_fr) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.1->textblob>=0.8.0->textblob_fr) (3.8.1)\n",
      "Installing collected packages: textblob_fr\n",
      "Successfully installed textblob_fr-0.2.0\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk -U\n",
    "!pip install tweepy -U\n",
    "!pip install textBlob -U\n",
    "!pip install textblob_fr -U\n",
    "!pip install numpy -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51971457-c123-40ee-8be7-df53ce3a67e1",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6387a8d-6ae8-4bb8-a5e2-1b594535aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from google.cloud import bigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c45541-1518-4323-88f8-8c674b4302bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "# from textblob_fr import PatternTagge\n",
    "import textblob_fr as tbfr\n",
    "\n",
    "PatternTagger = tbfr.PatternTagger\n",
    "PatternAnalyzer = tbfr.PatternAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d8e64-c2ba-43be-9a49-24e5f3b96479",
   "metadata": {},
   "source": [
    "### DEFINITION FONCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11078ba-564f-42af-810e-8446ce261967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nom_normalizer(equipe_a_normaliser):\n",
    "    teams = {\n",
    "        'OLYMPIQUE LYONNAIS': ['OLYMPIQUE LYONNAIS', 'LYON', 'OL', 'O.L.'], \n",
    "        'AC AJACCIO': ['AC AJACCIO', 'AJACCIO', 'ACA', 'A.C.A', 'ATHLETIC CLUB AJACCIEN','A-C AJACCIO','A.C AJACCIO'],\n",
    "        'RC STRASBOURG ALSACE' : ['STRASBOURG','RACING CLUB DE STRASBOURG ALSACE', 'RC STRASBOURG','R.C. STRASBOURG','R.C.S.','RCS', 'R.C.S.A.', 'RC STRASBOURG ALSACE', 'R.C. STRASBOURG ALSACE'], \n",
    "        'AS MONACO': ['AS MONACO', 'MONACO', 'ASSOCIATION SPORTIVE DE MONACO FOOTBALL CLUB', 'AS MONACO FC', 'A.S MONACO F.C', 'ASM'], \n",
    "        'CLERMONT FOOT 63': ['CLERMONT FOOT 63', 'CLERMONT-FERRAND', 'CF63', 'C.F.63', 'C-F 63', 'CLERMONT', 'CLERMONT FOOT'], \n",
    "        'PARIS SAINT GERMAIN': ['PARIS SAINT GERMAIN', 'PARIS-SAINT-GERMAIN FOOTBALL CLUB', 'PSG', 'P.S.G.', 'PARIS SG', 'PARIS-SG', 'PARIS SAINT-GERMAIN', 'PARIS SAINT-GERMAIN FOOTBALL CLUB', 'PARIS SAINT-GERMAIN FC'], \n",
    "        'TOULOUSE FC' : ['TOULOUSE', 'TOULOUSE FOOTBALL CLUB', 'TFC', 'T.F.C.', 'TOULOUSE FC', 'TOULOUSE F.C.'], \n",
    "        'OGC NICE': ['NICE', \"OLYMPIQUE GYMNASTE CLUB NICE COTE D'AZUR\", 'OGC NICE', 'O.G.C. NICE', \"OGC NICE COTE D'AZUR\", \"O.G.C. NICE COTE D'AZUR\", 'OLYMPIQUE GYMNASTE CLUB NICE'], \n",
    "        'ANGERS SCO': ['ANGERS SCO', 'ANGERS', \"SCO D'ANGERS\", 'SCOA', \"ANGERS SPORTING CLUB DE L'OUEST\", 'SCO ANGERS', 'ANGERS-SCO', 'ANGERS S.C.O.', 'S.C.O. ANGERS'], \n",
    "        'FC NANTES' : ['FC NANTES', 'NANTES', 'FOOTBALL CLUB DE NANTES', 'F.C. NANTES', 'FCN', 'F.C.N.'], \n",
    "        'RC LENS': ['RC LENS', 'LENS', 'RACING CLUB DE LENS', 'RCL', 'R.C.L.', 'R.C. LENS'], \n",
    "        'STADE BRESTOIS': ['STADE BRESTOIS', 'BREST', 'STADE BRESTOIS 29', 'SB29', 'S.B.29', 'S.B. 29'], \n",
    "        'LOSC LILLE': ['LOSC LILLE', 'LILLE', 'LOSC', 'LILLE OLYMPIQUE SPORTING CLUB', 'L.O.S.C.', 'L.O.S.C. LILLE'], \n",
    "        'AJ AUXERRE': ['AJ AUXERRE', 'AUXERRE', 'AJA', 'ASSOCIATION DE LA JEUNESSE AUXERROISE', 'A.J.AUXERRE', 'A.J AUXERRE'], \n",
    "        'MONTPELLIER HERAULT SC': ['MONTPELLIER HÃ‰RAULT SC', 'MONTPELLIER HÉRAULT SC','MONTPELLIER HÉRAULT', 'MONTPELLIER', 'MONTPELLIER-HERAULT SPORT CLUB', 'MONTPELLIER HERAULT SPORT CLUB', 'MONTPELLIER HSC', 'MHSC', 'MONTPELLIER-HERAULT SC', 'MONTPELLIER-HÉRAULT SC', 'MONTPELLIER-HERAULT S.C.', 'M.H.S.C.', 'MONTPELLIER HERAULT SC', 'MONTPELLIER HÉRAULT SC', 'MONTPELLIER HERAULT S.C.'], \n",
    "        'ESTAC TROYES': ['TROYES', 'ESPERANCE SPORTIVE TROYES AUBE CHAMPAGNE', 'ESTAC', 'E.S.T.A.C.', 'ESTAC TROYES', 'E.S.T.A.C. TROYES'], \n",
    "        'STADE RENNAIS FC': ['RENNES', 'STADE RENNAIS FOOTBALL CLUB', 'STADE RENNAIS', 'STADE RENNAIS FC', 'S.R.F.C.', 'STADE RENNAIS F.C.'], \n",
    "        'FC LORIENT': ['FC LORIENT', 'LORIENT', 'FOOTBALL CLUB LORIENT BRETAGNE SUD', 'FCL', 'F.C.L.', 'F.C. LORIENT', 'FC LORIENT BRETAGNE SUD', 'FOOTBALL CLUB LORIENTAIS'], \n",
    "        'OLYMPIQUE DE MARSEILLE': ['OLYMPIQUE DE MARSEILLE', 'MARSEILLE', 'OM', 'O.M.'],\n",
    "        'STADE DE REIMS': ['STADE DE REIMS', 'REIMS', 'STADE REIMS'],\n",
    "        'DIJON': ['DIJON', 'DIJON FCO', 'DFCO', \"DIJON FOOTBALL COTE-D'OR\", \"DIJON FOOTBALL CÔTE-D'OR\"],\n",
    "        'SAINT ETIENNE': ['ST ETIENNE', 'ST-ETIENNE', 'ST ÉTIENNE', 'ST-ÉTIENNE', 'SAINT ETIENNE', 'SAINT-ETIENNE', 'SAINT ÉTIENNE', 'SAINT-ÉTIENNE', 'ASSE','AS SAINT ETIENNE', 'AS SAINT-ETIENNE', 'AS SAINT-ÉTIENNE', 'AS SAINT-ÉTIENNE'],\n",
    "        'BORDEAUX': ['BORDEAUX', 'FOOTBALL CLUB DES GIRONDINS DE BORDEAUX', 'FC GIRONDINS DE BORDEAUX', 'GIRONDINS DE BORDEAUX', 'FCG BORDEAUX', 'FOOTBALL CLUB GIRONDINS DE BORDEAUX'],\n",
    "        'METZ': ['METZ', 'FC METZ', 'FOOTBALL CLUB DE METZ', 'FOOTBALL CLUB METZ']}\n",
    "    resultat = equipe_a_normaliser\n",
    "    for equipe_name in teams:\n",
    "        if equipe_a_normaliser in teams[equipe_name]:\n",
    "            return equipe_name\n",
    "    return resultat\n",
    "\n",
    "\n",
    "# Authentification pour utiliser API twitter\n",
    "def auth_cpt_twtr(consumer_key,consumer_secret,access_token,access_secret):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "        print('Successful Authentication')\n",
    "        return api\n",
    "    except:\n",
    "        print('Failed authentication')\n",
    "        exit()\n",
    "        \n",
    "def nlp_pipeline(dict_equipes:dict):\n",
    "    clean_tweets_equipes = {}\n",
    "    for equipe, tweets_equipe in dict_equipes.items():        \n",
    "        clean_tweets_equipe = []\n",
    "        for text in tweets_equipe:           \n",
    "            text = re.sub(r\"https?:\\/\\/\\S+\", \"\", text)\n",
    "            text = text.lower()\n",
    "            text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "            text = ' '.join(text.split())\n",
    "            text = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%°\\.]*\", \"\", text)\n",
    "            text = re.sub(r\"(\\s\\-\\s|-$)\", \"\", text)\n",
    "            text = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)\n",
    "            text = re.sub(r\"\\&\\S*\\s\", \"\", text)\n",
    "            text = re.sub(r\"\\&\", \"\", text)\n",
    "            text = re.sub(r\"\\+\", \"\", text)\n",
    "            text = re.sub(r\"\\#\", \"\", text)\n",
    "            text = re.sub(r\"\\$\", \"\", text)\n",
    "            text = re.sub(r\"\\£\", \"\", text)\n",
    "            text = re.sub(r\"\\%\", \"\", text)\n",
    "            text = re.sub(r\"\\:\", \"\", text)\n",
    "            text = re.sub(r\"\\@\", \"\", text)\n",
    "            text = re.sub(r\"\\-\", \" \", text)\n",
    "            text = re.compile(\"[\"\n",
    "                    u\"\\U0001F600-\\U0001F64F\" \n",
    "                    u\"\\U0001F300-\\U0001F5FF\" \n",
    "                    u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                    u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U000024C2-\\U0001F251\"\n",
    "                    u\"\\U0001f926-\\U0001f937\"\n",
    "                    u'\\U00010000-\\U0010ffff'\n",
    "                    u\"\\u200d\"\n",
    "                    u\"\\u2640-\\u2642\"\n",
    "                    u\"\\u2600-\\u2B55\"\n",
    "                    u\"\\u23cf\"\n",
    "                    u\"\\u23e9\"\n",
    "                    u\"\\u231a\"\n",
    "                    u\"\\u3030\"\n",
    "                    u\"\\ufe0f\" \n",
    "                            \"]+\", flags=re.UNICODE).sub(r'', text)\n",
    "            clean_tweets_equipe.append(text)\n",
    "        clean_tweets_equipes[equipe] = clean_tweets_equipe\n",
    "    return clean_tweets_equipes\n",
    "\n",
    "#chercher les tweets par les noms des équipes et par comptes\n",
    "def liste_equipes(path) -> set():\n",
    "    list_equipes = set()\n",
    "    clndr = pd.read_csv(path)\n",
    "    for index, line in clndr.iterrows():\n",
    "        list_equipes.add(line['Equipe HOME'])\n",
    "    return list_equipes\n",
    "    \n",
    "def nom_normalizer_q_twtr(equipe_a_normaliser):\n",
    "    teams = {\n",
    "        '#OL': ['OLYMPIQUE LYONNAIS', 'LYON', 'OL', 'O.L.'], \n",
    "        '#ACAjaccio': ['AC AJACCIO', 'AJACCIO', 'ACA', 'A.C.A', 'ATHLETIC CLUB AJACCIEN','A-C AJACCIO','A.C AJACCIO'],\n",
    "        '#RCSA' : ['STRASBOURG','RACING CLUB DE STRASBOURG ALSACE', 'RC STRASBOURG','R.C. STRASBOURG','R.C.S.','RCS', 'R.C.S.A.', 'RC STRASBOURG ALSACE', 'R.C. STRASBOURG ALSACE'], \n",
    "        '#ASMonaco OR #ASM': ['AS MONACO', 'MONACO', 'ASSOCIATION SPORTIVE DE MONACO FOOTBALL CLUB', 'AS MONACO FC', 'A.S MONACO F.C', 'ASM'], \n",
    "        '#CF63': ['CLERMONT FOOT 63', 'CLERMONT-FERRAND', 'CF63', 'C.F.63', 'C-F 63', 'CLERMONT', 'CLERMONT FOOT'], \n",
    "        '#PSG': ['PARIS SAINT GERMAIN', 'PARIS', 'PARIS-SAINT-GERMAIN FOOTBALL CLUB', 'PSG', 'P.S.G.', 'PARIS SG', 'PARIS-SG', 'PARIS SAINT-GERMAIN', 'PARIS SAINT-GERMAIN FOOTBALL CLUB', 'PARIS SAINT-GERMAIN FC'], \n",
    "        '#TFC' : ['TOULOUSE', 'TOULOUSE FOOTBALL CLUB', 'TFC', 'T.F.C.', 'TOULOUSE FC', 'TOULOUSE F.C.'], \n",
    "        '#OGCNice': ['NICE', \"OLYMPIQUE GYMNASTE CLUB NICE COTE D'AZUR\", 'OGC NICE', 'O.G.C. NICE', \"OGC NICE COTE D'AZUR\", \"O.G.C. NICE COTE D'AZUR\", 'OLYMPIQUE GYMNASTE CLUB NICE'], \n",
    "        '#SCO': ['ANGERS SCO', 'ANGERS', \"SCO D'ANGERS\", 'SCOA', \"ANGERS SPORTING CLUB DE L'OUEST\", 'SCO ANGERS', 'ANGERS-SCO', 'ANGERS S.C.O.', 'S.C.O. ANGERS'], \n",
    "        '#FCNantes OR #FCN' : ['FC NANTES', 'NANTES', 'FOOTBALL CLUB DE NANTES', 'F.C. NANTES', 'FCN', 'F.C.N.'], \n",
    "        '#RCLens OR #RCL': ['RC LENS', 'LENS', 'RACING CLUB DE LENS', 'RCL', 'R.C.L.', 'R.C. LENS'], \n",
    "        '#SB29': ['STADE BRESTOIS', 'BREST', 'STADE BRESTOIS 29', 'SB29', 'S.B.29', 'S.B. 29'], \n",
    "        '#LOSC': ['LOSC LILLE', 'LILLE', 'LOSC', 'LILLE OLYMPIQUE SPORTING CLUB', 'L.O.S.C.', 'L.O.S.C. LILLE'], \n",
    "        '#TeamAJA': ['AJ AUXERRE', 'AUXERRE', 'AJA', 'ASSOCIATION DE LA JEUNESSE AUXERROISE', 'A.J.AUXERRE', 'A.J AUXERRE'], \n",
    "        '#MHSC': ['MONTPELLIER HÃ‰RAULT SC', 'MONTPELLIER HÉRAULT SC','MONTPELLIER HÉRAULT', 'MONTPELLIER', 'MONTPELLIER-HERAULT SPORT CLUB', 'MONTPELLIER HERAULT SPORT CLUB', 'MONTPELLIER HSC', 'MHSC', 'MONTPELLIER-HERAULT SC', 'MONTPELLIER-HÉRAULT SC', 'MONTPELLIER-HERAULT S.C.', 'M.H.S.C.', 'MONTPELLIER HERAULT SC', 'MONTPELLIER HÉRAULT SC', 'MONTPELLIER HERAULT S.C.'], \n",
    "        '#ESTAC': ['TROYES', 'ESPERANCE SPORTIVE TROYES AUBE CHAMPAGNE', 'ESTAC', 'E.S.T.A.C.', 'ESTAC TROYES', 'E.S.T.A.C. TROYES'], \n",
    "        '#SRFC': ['RENNES', 'STADE RENNAIS FOOTBALL CLUB', 'STADE RENNAIS', 'STADE RENNAIS FC', 'S.R.F.C.', 'STADE RENNAIS F.C.'], \n",
    "        '#FCLorient': ['FC LORIENT', 'LORIENT', 'FOOTBALL CLUB LORIENT BRETAGNE SUD', 'FCL', 'F.C.L.', 'F.C. LORIENT', 'FC LORIENT BRETAGNE SUD', 'FOOTBALL CLUB LORIENTAIS'], \n",
    "        '#OM OR #teamOM': ['OLYMPIQUE DE MARSEILLE', 'MARSEILLE', 'OM', 'O.M.'],\n",
    "        '#GoSDR': ['STADE DE REIMS', 'REIMS', 'STADE REIMS']}\n",
    "    resultat = equipe_a_normaliser\n",
    "    for equipe_name in teams:\n",
    "        if equipe_a_normaliser in teams[equipe_name]:\n",
    "            return equipe_name\n",
    "    return resultat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6988a-8a47-49c1-9774-7a281b556340",
   "metadata": {},
   "source": [
    "## Parametres necessaires au fonctionnement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c1fe6d-1d29-4439-96e7-a34f394cb036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les chemins des dossiers dans le bucket\n",
    "path_bucket_gold = \"gs://bucket-git-m2i/DB/golden/\" \n",
    "\n",
    "currentDateTime = datetime.datetime.now()\n",
    "date = currentDateTime.date()\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "table_id = \"micro-atrium-360309.m2i_pronostics.polarity\"\n",
    "\n",
    "# pour execution schedulée, extraction de l'ID du projet temporaire créé\n",
    "project_number = os.environ[\"CLOUD_ML_PROJECT_ID\"]\n",
    "\n",
    "# credentials pour API Twitter\n",
    "api_key = \"BAbbm3LZTdxsvzDKocfLBlSGb\"\n",
    "api_key_secret = \"IZTYrFUUXJhNRauRxP95NkDgn7TsVymBPhsIICQFH2ZTulHHho\"\n",
    "access_token = \"1527657951317610504-7jMeN9wf8beUePhxNBfqojSa5k7wUl\"\n",
    "access_token_secret = \"Mmm1yQDKNDW2L09Ut4Rgvgyzs4lnvJzZuay7ga8vhDAG6\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2ceca-1bb2-4be9-a863-dba3c1a9bbf5",
   "metadata": {},
   "source": [
    "### Recuperer les tweets de chaque equipe et construire un BDD appendable avec les polarités correspondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3003b2eb-2b18-4b7e-8116-0692de637ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "#sys.stdout.reconfigure(encoding='utf-8')\n",
    "api = auth_cpt_twtr(api_key, api_key_secret, access_token, access_token_secret)\n",
    "\n",
    "equipes = list(liste_equipes(f'{path_bucket_gold}merging_calendrier.csv'))\n",
    "\n",
    "all_tweets = {}\n",
    "for equipe in equipes:\n",
    "    tweets_equipe = []\n",
    "    requete = nom_normalizer_q_twtr(equipe)\n",
    "    tweets = tweepy.Cursor(api.search_tweets,\n",
    "                    q= requete,\n",
    "                    lang= \"fr\").items(10)\n",
    "    for tweet in tweets:\n",
    "        tweets_equipe.append(tweet.text)\n",
    "    all_tweets[equipe] = tweets_equipe\n",
    "#print(all_tweets)\n",
    "\n",
    "#pipeline de nettoyage : enlever les ponctuations, emojis, mettre en miniscule...\n",
    "tweets_clean = nlp_pipeline(all_tweets)\n",
    "\n",
    "#calculer la polarité des tweets\n",
    "plt = pd.DataFrame(columns=['date','equipe','polarity'])\n",
    "for equipe, tweets_clean_eq in tweets_clean.items():\n",
    "    i=0\n",
    "    polarity=0\n",
    "    for tweet in tweets_clean_eq:\n",
    "        polarity+=TextBlob(tweet,pos_tagger=PatternTagger(),analyzer=PatternAnalyzer()).sentiment[0]\n",
    "        i+=1\n",
    "    avg_polarity = polarity/i\n",
    "    plt = plt.append({'date':date,'equipe':equipe,'polarity':avg_polarity}, ignore_index=True)\n",
    "plt.to_csv(f'{path_bucket_gold}polarity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96098e2",
   "metadata": {},
   "source": [
    "### Ajouter les resultats à la BDD existant polarity dans le BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4019b124-1b70-41ef-aabd-83ee4194439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 rows.\n"
     ]
    }
   ],
   "source": [
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client(project_number)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    skip_leading_rows=1,\n",
    "    write_disposition=\"WRITE_APPEND\",\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = f\"{path_bucket_gold}polarity.csv\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b19dd-87fd-4f45-ba54-903bbfa59caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m95"
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
