{"cells": [{"cell_type": "code", "execution_count": 2, "id": "df4b8a79-6aa3-4379-8bad-af5a23d8d48e", "metadata": {}, "outputs": [], "source": "from lxml import html\nimport requests\nimport pandas as pd\nfrom function import nom_normalizer"}, {"cell_type": "markdown", "id": "ce15e7de-0ff7-4d55-9df2-fabe92fec020", "metadata": {}, "source": "## Scrap du calendrier des matchs \u00e0 venir -> construction d'un fichier CSV par journ\u00e9e qui liste les 10 matchs (home, away, url)"}, {"cell_type": "code", "execution_count": 4, "id": "bcb23b27-d0e5-4fc7-a9b5-910431b8ec78", "metadata": {}, "outputs": [], "source": "# journ\u00e9e \u00e0 scrapper\nfor journee in range(1,39): # journ\u00e9e de 1 \u00e0 23 (index final = 24-1)\n    # url de la site \u00e0 scrapper\n    url_a_scrapper = f\"https://www.ligue1.fr/calendrier-resultats?seasonId=2022-2023&matchDay={journee}\"\n    # url principale de la site\n    url_base = \"https://www.ligue1.fr\"\n    # request pour avoir le corps de code de la page \u00e0 scrapper\n    resp = requests.get(url_a_scrapper)\n    # trier la contnue du code de la page comme un arbre de html\n    tree = html.fromstring(resp.content)\n\n    # scrape toutes les id des matchs dans la page\n    match_id = []\n    match_id_code = tree.xpath('/html/body/main/div[3]/div[2]/div/div[2]/ul[*]/li/a/div[2]')\n    for each_id in match_id_code:\n        # if va chercher dans chaque balise a id son contenu \n        # et l'ajouter dans la liste de match_id\n        match_id.append(each_id.attrib[\"id\"])\n\n    # recuperer les elements \u00e0 chercher par leurs xpath\n    equipe_home = []\n    equipe_away = []\n    match_href = []\n    match_url = []\n    i=0\n    for each_id in match_id:\n        # le resultat de tree.xpath sera en forme de liste \n        # il faut index[0] et .text pour recuperer le contenu\n        equipe_home.append(nom_normalizer(tree.xpath(f'//*[@id=\"{each_id}_match-result\"]/a/div[1]/div/span[1]')[0].text))\n        equipe_away.append(nom_normalizer(tree.xpath(f'//*[@id=\"{each_id}_match-result\"]/a/div[3]/div/span[1]')[0].text))\n        # Afin d'avoir acceder \u00e0 la page de detailles de match\n        # on scrape le lien de chaque match et on l'ajout \u00e0 la url_base\n        # afin de deviner un lien complet\n        # ici le resultat de tree.xpath a plusieurs attributes\n        # donc on choisis l'attribue concern\u00e9 par [0].attrib[\"href\"]\n        # href c'est l'attribue nous interesse\n        match_href.append(tree.xpath(f'//*[@id=\"{each_id}_match-result\"]/a'))\n        match_url.append(url_base + match_href[i][0].attrib[\"href\"])\n        i+=1\n#     for i in range(10):\n#         print(i+1,\" - \",equipe_home[i],\"\\t\", equipe_away[i],\"\\n url: \", match_url[i],\"\\n\")\n\n    # zipper les informations des listes dans un dataframe\n    # avec 3 columns correspondant \u00e0 chaque liste\n    # et les sauvegarder dans un fichier CSV\n    df_journee_1 = pd.DataFrame(list(zip(equipe_home, equipe_away, match_url)), \n                        columns =['Equipe HOME', 'Equipe AWAY', 'URL']) \n    df_journee_1.to_csv(f'gs://m2i_pronostics/DB/calendrier/journee_{journee}.csv', index=False)"}, {"cell_type": "code", "execution_count": null, "id": "83b221d2", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 5}