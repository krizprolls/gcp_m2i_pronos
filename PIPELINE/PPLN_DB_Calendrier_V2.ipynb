{"cells":[{"cell_type":"markdown","id":"14e92976-2559-4e72-8d14-1c2dd4477ef1","metadata":{},"source":["# --> PIPELINE QUI scrap du calendrier des matchs à venir \n","### --> construction 38 fichiers CSV 1 par journée qui liste les 10 matchs (home, away, url)\n","### --> assembler toutes les données dans les fichiers csv dans un seul BDD Calendrier (380 lignes)"]},{"cell_type":"markdown","id":"51971457-c123-40ee-8be7-df53ce3a67e1","metadata":{},"source":["### IMPORTER les Libraries nécessaires au fonctionnement"]},{"cell_type":"code","execution_count":null,"id":"b6387a8d-6ae8-4bb8-a5e2-1b594535aa93","metadata":{"scrolled":true},"outputs":[],"source":["import os\n","import pandas as pd\n","from lxml import html\n","import requests\n","from google.cloud import bigquery\n"]},{"cell_type":"markdown","id":"4c7d8e64-c2ba-43be-9a49-24e5f3b96479","metadata":{},"source":["### DEFINITION FONCTIONS"]},{"cell_type":"code","execution_count":null,"id":"a11078ba-564f-42af-810e-8446ce261967","metadata":{},"outputs":[],"source":["def nom_normalizer(equipe_a_normaliser):\n","    teams = {\n","        'OLYMPIQUE LYONNAIS': ['OLYMPIQUE LYONNAIS', 'LYON', 'OL', 'O.L.'], \n","        'AC AJACCIO': ['AC AJACCIO', 'AJACCIO', 'ACA', 'A.C.A', 'ATHLETIC CLUB AJACCIEN','A-C AJACCIO','A.C AJACCIO'],\n","        'RC STRASBOURG ALSACE' : ['STRASBOURG','RACING CLUB DE STRASBOURG ALSACE', 'RC STRASBOURG','R.C. STRASBOURG','R.C.S.','RCS', 'R.C.S.A.', 'RC STRASBOURG ALSACE', 'R.C. STRASBOURG ALSACE'], \n","        'AS MONACO': ['AS MONACO', 'MONACO', 'ASSOCIATION SPORTIVE DE MONACO FOOTBALL CLUB', 'AS MONACO FC', 'A.S MONACO F.C', 'ASM'], \n","        'CLERMONT FOOT 63': ['CLERMONT FOOT 63', 'CLERMONT-FERRAND', 'CF63', 'C.F.63', 'C-F 63', 'CLERMONT', 'CLERMONT FOOT'], \n","        'PARIS SAINT GERMAIN': ['PARIS SAINT GERMAIN', 'PARIS-SAINT-GERMAIN FOOTBALL CLUB', 'PSG', 'P.S.G.', 'PARIS SG', 'PARIS-SG', 'PARIS SAINT-GERMAIN', 'PARIS SAINT-GERMAIN FOOTBALL CLUB', 'PARIS SAINT-GERMAIN FC'], \n","        'TOULOUSE FC' : ['TOULOUSE', 'TOULOUSE FOOTBALL CLUB', 'TFC', 'T.F.C.', 'TOULOUSE FC', 'TOULOUSE F.C.'], \n","        'OGC NICE': ['NICE', \"OLYMPIQUE GYMNASTE CLUB NICE COTE D'AZUR\", 'OGC NICE', 'O.G.C. NICE', \"OGC NICE COTE D'AZUR\", \"O.G.C. NICE COTE D'AZUR\", 'OLYMPIQUE GYMNASTE CLUB NICE'], \n","        'ANGERS SCO': ['ANGERS SCO', 'ANGERS', \"SCO D'ANGERS\", 'SCOA', \"ANGERS SPORTING CLUB DE L'OUEST\", 'SCO ANGERS', 'ANGERS-SCO', 'ANGERS S.C.O.', 'S.C.O. ANGERS'], \n","        'FC NANTES' : ['FC NANTES', 'NANTES', 'FOOTBALL CLUB DE NANTES', 'F.C. NANTES', 'FCN', 'F.C.N.'], \n","        'RC LENS': ['RC LENS', 'LENS', 'RACING CLUB DE LENS', 'RCL', 'R.C.L.', 'R.C. LENS'], \n","        'STADE BRESTOIS': ['STADE BRESTOIS', 'BREST', 'STADE BRESTOIS 29', 'SB29', 'S.B.29', 'S.B. 29'], \n","        'LOSC LILLE': ['LOSC LILLE', 'LILLE', 'LOSC', 'LILLE OLYMPIQUE SPORTING CLUB', 'L.O.S.C.', 'L.O.S.C. LILLE'], \n","        'AJ AUXERRE': ['AJ AUXERRE', 'AUXERRE', 'AJA', 'ASSOCIATION DE LA JEUNESSE AUXERROISE', 'A.J.AUXERRE', 'A.J AUXERRE'], \n","        'MONTPELLIER HERAULT SC': ['MONTPELLIER HÃ‰RAULT SC', 'MONTPELLIER HÉRAULT SC','MONTPELLIER HÉRAULT', 'MONTPELLIER', 'MONTPELLIER-HERAULT SPORT CLUB', 'MONTPELLIER HERAULT SPORT CLUB', 'MONTPELLIER HSC', 'MHSC', 'MONTPELLIER-HERAULT SC', 'MONTPELLIER-HÉRAULT SC', 'MONTPELLIER-HERAULT S.C.', 'M.H.S.C.', 'MONTPELLIER HERAULT SC', 'MONTPELLIER HÉRAULT SC', 'MONTPELLIER HERAULT S.C.'], \n","        'ESTAC TROYES': ['TROYES', 'ESPERANCE SPORTIVE TROYES AUBE CHAMPAGNE', 'ESTAC', 'E.S.T.A.C.', 'ESTAC TROYES', 'E.S.T.A.C. TROYES'], \n","        'STADE RENNAIS FC': ['RENNES', 'STADE RENNAIS FOOTBALL CLUB', 'STADE RENNAIS', 'STADE RENNAIS FC', 'S.R.F.C.', 'STADE RENNAIS F.C.'], \n","        'FC LORIENT': ['FC LORIENT', 'LORIENT', 'FOOTBALL CLUB LORIENT BRETAGNE SUD', 'FCL', 'F.C.L.', 'F.C. LORIENT', 'FC LORIENT BRETAGNE SUD', 'FOOTBALL CLUB LORIENTAIS'], \n","        'OLYMPIQUE DE MARSEILLE': ['OLYMPIQUE DE MARSEILLE', 'MARSEILLE', 'OM', 'O.M.'],\n","        'STADE DE REIMS': ['STADE DE REIMS', 'REIMS', 'STADE REIMS'],\n","        'DIJON': ['DIJON', 'DIJON FCO', 'DFCO', \"DIJON FOOTBALL COTE-D'OR\", \"DIJON FOOTBALL CÔTE-D'OR\"],\n","        'SAINT ETIENNE': ['ST ETIENNE', 'ST-ETIENNE', 'ST ÉTIENNE', 'ST-ÉTIENNE', 'SAINT ETIENNE', 'SAINT-ETIENNE', 'SAINT ÉTIENNE', 'SAINT-ÉTIENNE', 'ASSE','AS SAINT ETIENNE', 'AS SAINT-ETIENNE', 'AS SAINT-ÉTIENNE', 'AS SAINT-ÉTIENNE'],\n","        'BORDEAUX': ['BORDEAUX', 'FOOTBALL CLUB DES GIRONDINS DE BORDEAUX', 'FC GIRONDINS DE BORDEAUX', 'GIRONDINS DE BORDEAUX', 'FCG BORDEAUX', 'FOOTBALL CLUB GIRONDINS DE BORDEAUX'],\n","        'METZ': ['METZ', 'FC METZ', 'FOOTBALL CLUB DE METZ', 'FOOTBALL CLUB METZ']}\n","    resultat = equipe_a_normaliser\n","    for equipe_name in teams:\n","        if equipe_a_normaliser in teams[equipe_name]:\n","            return equipe_name\n","    return resultat\n"]},{"cell_type":"markdown","id":"ac8c7d42-6fe3-461a-9087-50d617ef2c7b","metadata":{},"source":["## Paramètres à régler selon les chemins d'acces dans le GCP"]},{"cell_type":"code","execution_count":null,"id":"deafcdfb","metadata":{},"outputs":[],"source":["# nombre des jours de la saison à scrapper\n","nombre_jrnes = 38\n","\n","# les chemins des dossiers dans le bucket\n","path_bucket_lake = \"gs://data-lake-m2i/DB/calendrier/\"\n","path_bucket_gold = \"gs://data-lake-m2i/DB/golden/\"\n","\n","# TODO(developer): Set table_id to the ID of the table to create.\n","table_id = \"involuted-disk-355708.m2i_pronos_test.calendrier-season\""]},{"cell_type":"markdown","id":"20e0d055","metadata":{},"source":["## Scrap du calendrier des matchs à venir -> construction d'un fichier CSV par journée qui liste les 10 matchs (home, away, url)"]},{"cell_type":"code","execution_count":null,"id":"fca66b4a-ddee-4ad1-a405-f3240cf627e8","metadata":{},"outputs":[],"source":["# journée à scrapper\n","for journee in range(1,nombre_jrnes+1): \n","    # url de la site à scrapper\n","    url_a_scrapper = f\"https://www.ligue1.fr/calendrier-resultats?seasonId=2022-2023&matchDay={journee}\"\n","    # url principale de la site\n","    url_base = \"https://www.ligue1.fr\"\n","    # request pour avoir le corps de code de la page à scrapper\n","    resp = requests.get(url_a_scrapper)\n","    # trier la contnue du code de la page comme un arbre de html\n","    tree = html.fromstring(resp.content)\n","\n","    # scrape toutes les id des matchs dans la page\n","    match_id = []\n","    match_id_code = tree.xpath('/html/body/main/div[3]/div[2]/div/div[2]/ul[*]/li/a/div[2]')\n","    for each_id in match_id_code:\n","        # if va chercher dans chaque balise a id son contenu \n","        # et l'ajouter dans la liste de match_id\n","        match_id.append(each_id.attrib[\"id\"])\n","\n","    # recuperer les elements à chercher par leurs xpath\n","    equipe_home = []\n","    equipe_away = []\n","    match_href = []\n","    match_url = []\n","    i=0\n","    for each_id in match_id:\n","        # le resultat de tree.xpath sera en forme de liste \n","        # il faut index[0] et .text pour recuperer le contenu\n","        equipe_home.append(nom_normalizer(tree.xpath(f'//*[@id=\"{each_id}_match-result\"]/a/div[1]/div/span[1]')[0].text))\n","        equipe_away.append(nom_normalizer(tree.xpath(f'//*[@id=\"{each_id}_match-result\"]/a/div[3]/div/span[1]')[0].text))\n","        # Afin d'avoir acceder à la page de detailles de match\n","        # on scrape le lien de chaque match et on l'ajout à la url_base\n","        # afin de deviner un lien complet\n","        # ici le resultat de tree.xpath a plusieurs attributes\n","        # donc on choisis l'attribue concerné par [0].attrib[\"href\"]\n","        # href c'est l'attribue nous interesse\n","        match_href.append(tree.xpath(f'//*[@id=\"{each_id}_match-result\"]/a'))\n","        match_url.append(url_base + match_href[i][0].attrib[\"href\"])\n","        i+=1\n","    # zipper les informations des listes dans un dataframe\n","    # avec 3 columns correspondant à chaque liste\n","    # et les sauvegarder dans un fichier CSV\n","    df_journee_1 = pd.DataFrame(list(zip(equipe_home, equipe_away, match_url)), \n","                        columns =['Equipe HOME', 'Equipe AWAY', 'URL']) \n","    df_journee_1.to_csv(f'{path_bucket_lake}journee_{journee}.csv', index=False)"]},{"cell_type":"markdown","id":"99d1d26d-f6a8-4efe-8c05-6c13fb37d5fa","metadata":{},"source":["## Merging des csv issus du scrap calendrier -> construction d'un csv qui comprend la journée, home, away et l'url"]},{"cell_type":"code","execution_count":null,"id":"62f2c8c2-ca80-4ef6-8272-c4c7fab28e8c","metadata":{},"outputs":[],"source":["# liste vide pour accumeler dedans les dataframe de chaque journée\n","dataframes = []\n","\n","# ajouter les données de chaque journée à la liste dataframes\n","for num in range(1,nombre_jrnes+1):\n","    df_journee = pd.read_csv(f\"{path_bucket_lake}journee_{num}.csv\")# storage_options={\"token\":\"cloud\"})\n","    df_journee.insert(0, \"Journee\", num)\n","    dataframes.append(df_journee)\n","\n","# concatener la liste des dataframe et la transformer en csv dans le bucket golden\n","pd.concat(dataframes).to_csv(f\"{path_bucket_gold}merging_calendrier.csv\", index=False) #,mode=\"w\")    \n"]},{"cell_type":"markdown","id":"af8f70bd-ffd6-4a2c-90c0-1926d5270257","metadata":{},"source":["### Le csv créé (merging_calendrier) est importé dans un dataset bigQuery (en écrasant les donnnées)"]},{"cell_type":"code","execution_count":null,"id":"cb936434-c307-4208-8503-6216447936a5","metadata":{},"outputs":[],"source":["# Construct a BigQuery client object.\n","client = bigquery.Client()\n","\n","job_config = bigquery.LoadJobConfig(\n","    skip_leading_rows=1,\n","    write_disposition=\"WRITE_TRUNCATE\",\n","    # The source format defaults to CSV, so the line below is optional.\n","    source_format=bigquery.SourceFormat.CSV,\n",")\n","uri = f\"{path_bucket_gold}merging_calendrier.csv\"\n","\n","load_job = client.load_table_from_uri(\n","    uri, table_id, job_config=job_config\n",")  # Make an API request.\n","\n","load_job.result()  # Waits for the job to complete.\n","\n","destination_table = client.get_table(table_id)  # Make an API request.\n","print(\"Loaded {} rows.\".format(destination_table.num_rows))"]},{"cell_type":"code","execution_count":null,"id":"78451cdb","metadata":{},"outputs":[],"source":[]}],"metadata":{"environment":{"kernel":"python3","name":"common-cu110.m95","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cu110:m95"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":5}